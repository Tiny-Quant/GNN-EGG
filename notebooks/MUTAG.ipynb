{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUTAG Model\n",
    "\n",
    "- Reference: https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing#scrollTo=mHSP6-RBOqCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import torch \n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "from egg_models.egg_generic_losses import activation_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True \n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data. \n",
    "data_raw = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "\n",
    "# Shuffle\n",
    "data_raw = data_raw.shuffle()\n",
    "\n",
    "# Split \n",
    "train_data = data_raw[:150]\n",
    "test_data = data_raw[150:]\n",
    "\n",
    "# Create data lists\n",
    "train_data_list = []\n",
    "train_data_list_0 = []\n",
    "train_data_list_1 = []\n",
    "test_data_list = []\n",
    "test_data_list_0 = []\n",
    "test_data_list_1 = []\n",
    "\n",
    "for graph in train_data:\n",
    "    train_data_list.append(graph)\n",
    "\n",
    "    if graph.y.item() == 0: \n",
    "        train_data_list_0.append(graph)\n",
    "\n",
    "    elif graph.y.item() == 1: \n",
    "        train_data_list_1.append(graph)\n",
    "\n",
    "for graph in test_data:\n",
    "    test_data_list.append(graph)\n",
    "\n",
    "    if graph.y.item() == 0: \n",
    "        test_data_list_0.append(graph)\n",
    "\n",
    "    elif graph.y.item() == 1: \n",
    "        test_data_list_1.append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Explainee Model \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(7, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Accuracy: 0.6533333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 1 Train Accuracy: 0.6533333333333333 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 2 Train Accuracy: 0.6733333333333333 Test Accuracy: 0.7368421052631579\n",
      "Epoch: 3 Train Accuracy: 0.74 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 4 Train Accuracy: 0.7066666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 5 Train Accuracy: 0.7066666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 6 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 7 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 8 Train Accuracy: 0.74 Test Accuracy: 0.7894736842105263\n",
      "Epoch: 9 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.7894736842105263\n",
      "Epoch: 10 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.7631578947368421\n",
      "Epoch: 11 Train Accuracy: 0.74 Test Accuracy: 0.7894736842105263\n",
      "Epoch: 12 Train Accuracy: 0.72 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 13 Train Accuracy: 0.74 Test Accuracy: 0.7105263157894737\n",
      "Epoch: 14 Train Accuracy: 0.7333333333333333 Test Accuracy: 0.7894736842105263\n",
      "Epoch: 15 Train Accuracy: 0.7133333333333334 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 16 Train Accuracy: 0.7333333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 17 Train Accuracy: 0.72 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 18 Train Accuracy: 0.74 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 19 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 20 Train Accuracy: 0.7266666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 21 Train Accuracy: 0.74 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 22 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 23 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 24 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 25 Train Accuracy: 0.7266666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 26 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 27 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 28 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 29 Train Accuracy: 0.7333333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 30 Train Accuracy: 0.7266666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 31 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 32 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 33 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 34 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 35 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 36 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 37 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 38 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 39 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 40 Train Accuracy: 0.74 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 41 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 42 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 43 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 44 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 45 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 46 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 47 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 48 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 49 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 50 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 51 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 52 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 53 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 54 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 55 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 56 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 57 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 58 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 59 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 60 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 61 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 62 Train Accuracy: 0.7333333333333333 Test Accuracy: 0.868421052631579\n",
      "Epoch: 63 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 64 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 65 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 66 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 67 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 68 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 69 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 70 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 71 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 72 Train Accuracy: 0.74 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 73 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 74 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 75 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 76 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 77 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 78 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 79 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 80 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 81 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 82 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 83 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 84 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 85 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 86 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 87 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 88 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 89 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 90 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 91 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 92 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 93 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 94 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 95 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 96 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 97 Train Accuracy: 0.76 Test Accuracy: 0.7894736842105263\n",
      "Epoch: 98 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 99 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 100 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 101 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 102 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 103 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 104 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 105 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 106 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 107 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 108 Train Accuracy: 0.7333333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 109 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 110 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 111 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 112 Train Accuracy: 0.7333333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 113 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 114 Train Accuracy: 0.74 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 115 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 116 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 117 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 118 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 119 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 120 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 121 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 122 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 123 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 124 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 125 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 126 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 127 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 128 Train Accuracy: 0.7333333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 129 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 130 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 131 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 132 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 133 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 134 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 135 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 136 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 137 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 138 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 139 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 140 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 141 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 142 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 143 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 144 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 145 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 146 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 147 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 148 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 149 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 150 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 151 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 152 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 153 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 154 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 155 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 156 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 157 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 158 Train Accuracy: 0.7866666666666666 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 159 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 160 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 161 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 162 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 163 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 164 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 165 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 166 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 167 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 168 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 169 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 170 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 171 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 172 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 173 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 174 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 175 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 176 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 177 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 178 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 179 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 180 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 181 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 182 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 183 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 184 Train Accuracy: 0.7466666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 185 Train Accuracy: 0.78 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 186 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 187 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 188 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 189 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 190 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 191 Train Accuracy: 0.78 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 192 Train Accuracy: 0.78 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 193 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 194 Train Accuracy: 0.7733333333333333 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 195 Train Accuracy: 0.7666666666666667 Test Accuracy: 0.8157894736842105\n",
      "Epoch: 196 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 197 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 198 Train Accuracy: 0.76 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 199 Train Accuracy: 0.7533333333333333 Test Accuracy: 0.8421052631578947\n",
      "Epoch: 200 Train Accuracy: 0.76 Test Accuracy: 0.8157894736842105\n"
     ]
    }
   ],
   "source": [
    "# Train explainee model \n",
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(data_loader): \n",
    "    model.train()\n",
    "\n",
    "    for batch in data_loader: \n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def model_accuracy(data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for batch in data_loader: \n",
    "        out = model(batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == batch.y).sum())\n",
    "\n",
    "    return correct / len(data_loader.dataset)\n",
    "\n",
    "train_data_loader = pyg.loader.DataLoader(train_data_list, \n",
    "                                          batch_size=16, shuffle=True)\n",
    "\n",
    "test_data_loader = pyg.loader.DataLoader(test_data_list, \n",
    "                                          batch_size=16, shuffle=False)\n",
    "\n",
    "for epoch in range(201): \n",
    "    train(train_data_loader)\n",
    "    train_accuracy = model_accuracy(train_data_loader)\n",
    "    test_accuracy = model_accuracy(test_data_loader)\n",
    "\n",
    "    print(f\"Epoch: {epoch} Train Accuracy: {train_accuracy} \" + \n",
    "          f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv2': tensor([[-0.2915, -1.8095, -0.2189, -0.1180, -0.2793, -0.2710, -2.0111, -0.3490,\n",
      "         -0.9480, -1.5090, -0.4723, -0.1447, -0.9340, -0.9859, -0.1834, -0.3930,\n",
      "         -1.3659, -0.3043, -0.7467, -0.2003, -0.1981, -0.9850, -0.1815, -0.4189,\n",
      "         -0.9779, -0.3608, -0.2256, -0.2999, -0.1910, -0.2666, -1.5029, -1.8962,\n",
      "         -0.5124, -1.0498, -0.0932, -0.4114, -0.1367, -0.4498, -0.1757, -0.1389,\n",
      "         -0.3753, -0.1467, -2.1132, -0.1634, -0.7426, -0.2079, -0.3401, -0.3812,\n",
      "         -0.2202, -1.8615, -0.8407, -0.3386, -0.2537, -1.7592, -0.3878, -0.5448,\n",
      "         -0.2084, -0.4950, -2.0607, -0.3693, -1.4028, -1.0697, -0.4403, -0.4440]]), 'conv3': tensor([[ 0.1202,  0.0301, -0.1539,  0.0836, -0.3402, -0.1375, -0.1699,  0.0640,\n",
      "         -0.1472, -0.0222, -0.1640,  0.3020, -0.2556,  0.0745,  0.1479, -0.1212,\n",
      "          0.0636,  0.0140, -0.0713,  0.1265, -0.1106, -0.0566,  0.0307,  0.0153,\n",
      "          0.0102,  0.1602, -0.0802,  0.0850,  0.1408,  0.1291,  0.0837, -0.0738,\n",
      "          0.0906, -0.2019, -0.1980, -0.0729,  0.0614, -0.0995, -0.0143, -0.0739,\n",
      "         -0.0042,  0.0854,  0.1329, -0.0447, -0.2485, -0.2169, -0.1949, -0.1705,\n",
      "          0.0203, -0.1435, -0.1448, -0.1260, -0.1088,  0.0652, -0.1992, -0.1644,\n",
      "         -0.2817, -0.1563, -0.1211,  0.1561,  0.1265,  0.0690,  0.1022,  0.0133]])}\n",
      "{'conv2': tensor([[-0.2515, -1.2812, -0.2207, -0.1134, -0.2370, -0.2211, -1.4130, -0.3101,\n",
      "         -0.8334, -1.1546, -0.3616, -0.1357, -0.8055, -0.8784, -0.1821, -0.3496,\n",
      "         -1.0350, -0.3092, -0.6668, -0.1929, -0.1761, -0.8472, -0.1710, -0.3294,\n",
      "         -0.8706, -0.3082, -0.2125, -0.2582, -0.1394, -0.2384, -1.1306, -1.3647,\n",
      "         -0.5365, -0.8062, -0.0897, -0.3538, -0.1225, -0.3488, -0.1530, -0.1139,\n",
      "         -0.3364, -0.1325, -1.5076, -0.1377, -0.5904, -0.1964, -0.3155, -0.3352,\n",
      "         -0.2040, -1.3148, -0.6298, -0.2972, -0.2301, -1.3308, -0.3550, -0.4315,\n",
      "         -0.1887, -0.4557, -1.4606, -0.3578, -1.0381, -0.7812, -0.3806, -0.3433]]), 'conv3': tensor([[ 0.0084, -0.1011, -0.1093, -0.1223, -0.4940, -0.3577,  0.0099, -0.1588,\n",
      "         -0.0343,  0.0984,  0.0275,  0.1901, -0.0732, -0.1095, -0.0661,  0.0944,\n",
      "         -0.1478, -0.2384,  0.0805, -0.0282, -0.1894,  0.0490, -0.0048, -0.1445,\n",
      "         -0.0182, -0.0510,  0.0944,  0.3359,  0.0612,  0.0290,  0.1819, -0.3560,\n",
      "          0.0045,  0.0035, -0.0468, -0.0859, -0.0958, -0.0600, -0.0164,  0.0510,\n",
      "          0.0322,  0.3357, -0.0259,  0.0222, -0.0948, -0.1394, -0.1031, -0.0091,\n",
      "          0.0058, -0.0266,  0.0851, -0.1699,  0.0338, -0.1087, -0.1067, -0.0218,\n",
      "         -0.1415, -0.0191,  0.0351, -0.0632, -0.0422, -0.1331, -0.0298,  0.2788]])}\n"
     ]
    }
   ],
   "source": [
    "# Extract average embeddings.\n",
    "activation_names = [\"conv2\", \"conv3\"]\n",
    "train_avg_embedding_0 = {\"conv2\": [], \"conv3\": []}\n",
    "train_avg_embedding_1 = {\"conv2\": [], \"conv3\": []}\n",
    "pool_func = pyg.nn.global_mean_pool\n",
    "\n",
    "train_data_loader_1 = pyg.loader.DataLoader(train_data_list)\n",
    "for batch in train_data_loader_1:\n",
    "    model.eval()\n",
    "\n",
    "    acts, remove_hooks = activation_hook(model, activation_names)\n",
    "    out = model(batch)\n",
    "    remove_hooks()\n",
    "\n",
    "    if batch.y.item() == 0: \n",
    "        for name in activation_names: \n",
    "            embed = pool_func(acts[name], batch.batch)\n",
    "            train_avg_embedding_0[name].append(\n",
    "                embed.detach().to('cpu')\n",
    "            )\n",
    "\n",
    "    if batch.y.item() == 1: \n",
    "        for name in activation_names: \n",
    "            embed = pool_func(acts[name], batch.batch)\n",
    "            train_avg_embedding_1[name].append(\n",
    "                embed.detach().to('cpu')\n",
    "            )\n",
    "            \n",
    "for name in activation_names:\n",
    "    train_avg_embedding_0[name] = torch.stack(\n",
    "        train_avg_embedding_0[name]\n",
    "    ).mean(dim=0)\n",
    "\n",
    "    train_avg_embedding_1[name] = torch.stack(\n",
    "        train_avg_embedding_1[name]\n",
    "    ).mean(dim=0)\n",
    "\n",
    "print(train_avg_embedding_0)\n",
    "print(train_avg_embedding_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data. \n",
    "import dill as pickle \n",
    "base_path = \"../data/explainees/MUTAG/\"\n",
    "\n",
    "# Save model weights. \n",
    "torch.save(model.state_dict(), base_path + \"gcn_200.pt\")\n",
    "\n",
    "with open(base_path + \"MUTAG_train_data_list.pkl\", 'wb') as f:\n",
    "    pickle.dump(train_data_list, f)\n",
    "with open(base_path + \"MUTAG_train_data_list_0.pkl\", 'wb') as f:\n",
    "    pickle.dump(train_data_list_0, f)\n",
    "with open(base_path + \"MUTAG_train_data_list.pkl_1\", 'wb') as f:\n",
    "    pickle.dump(train_data_list_1, f)\n",
    "    \n",
    "with open(base_path + \"MUTAG_test_data_list.pkl\", 'wb') as f:\n",
    "    pickle.dump(test_data_list, f)\n",
    "with open(base_path + \"MUTAG_test_data_list_0.pkl\", 'wb') as f:\n",
    "    pickle.dump(test_data_list_0, f)\n",
    "with open(base_path + \"MUTAG_test_data_list_1.pkl\", 'wb') as f:\n",
    "    pickle.dump(test_data_list_1, f)\n",
    "\n",
    "with open(base_path + \"MUTAG_train_avg_embedding_dict_0.pkl\", 'wb') as f:\n",
    "    pickle.dump(train_avg_embedding_0, f)\n",
    "\n",
    "with open(base_path + \"MUTAG_train_avg_embedding_dict_1.pkl\", 'wb') as f:\n",
    "    pickle.dump(train_avg_embedding_1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 14:00:10.182825: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-19 14:00:28.013681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import mutag_helper\n",
    "from egg_models.egg_generic import EggGeneric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.mutag_helper' from '/endosome/work/DPDS/s224833/Dissertation/gnn-egg/notebooks/../utils/mutag_helper.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(mutag_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = EggGeneric(5, None, (7,), None, (4, ), batch_size=16)\n",
    "generator.AdjacencyMatrix.probs = torch.nn.Parameter(\n",
    "    torch.zeros_like(generator.AdjacencyMatrix.probs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986],\n",
       "        [ 0.1681, -0.3986]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_dict = generator()\n",
    "gen_ex = mutag_helper.egg_to_ex(gen_dict)\n",
    "model(gen_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "test = torch.tensor([2., 2., 1.])\n",
    "test2 = torch.ones_like(test) * test.mode().values\n",
    "test2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 ('egg-env-38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acb8e8b27e9ec0ed29902217e0d03ed451ab18a07bb1e74a3ab78cd1bdd2a7c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
